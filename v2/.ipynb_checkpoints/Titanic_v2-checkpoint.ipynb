{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zemIDAqEc6if",
    "outputId": "19ae7b65-d0c9-4839-bb51-16af8c39328c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16758/1324450713.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MAvqVL8Oc6ig"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P3IR3c_1c6ig"
   },
   "outputs": [],
   "source": [
    "def try_float(s):\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def str_to_float_encode(s):\n",
    "    ord_strs = [ str(ord(c)) for c in s ]\n",
    "    ord_str = ''.join(ord_strs) if ord_strs else '-1.0'\n",
    "    return float(ord_str)\n",
    "\n",
    "def str_to_float(s):\n",
    "    f = try_float(s)\n",
    "    return f if f is not None else str_to_float_encode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Xe7DD3Yc6ig",
    "outputId": "99a7ab5f-5a63-4125-d974-7f5cd3d7f39d"
   },
   "outputs": [],
   "source": [
    "#input_path = '../input/titanic/train.csv'\n",
    "input_path = '../train.csv'\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    _ = next(reader)\n",
    "    samples = []\n",
    "    targets = []\n",
    "\n",
    "    for row in reader:\n",
    "        target = int(row[1])\n",
    "        targets.append(target)\n",
    "\n",
    "        samp = [str_to_float(v) for v in row[2:]]\n",
    "        samples.append(samp)\n",
    "        #print(samp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XyVX3Zklc6ii",
    "outputId": "418253c8-4288-4119-e0a0-3d681c1194e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples), len(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zNhQ1j7O-cEt"
   },
   "outputs": [],
   "source": [
    "sample_tensor = torch.tensor(samples)\n",
    "sample_ndarray = np.array(samples)\n",
    "sample_df = pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z078djk1Ev8d",
    "outputId": "67f6bbc9-af4a-475e-cec3-afc792477f41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1    888\n",
       "2      2\n",
       "3     89\n",
       "4      7\n",
       "5      7\n",
       "6    638\n",
       "7    248\n",
       "8    148\n",
       "9      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRc1ppbTDZVX",
    "outputId": "6c014bda-f69c-4592-8fe1-224c1565829f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000e+00,  8.7101e+37,  1.0997e+10,  ...,  2.6550e+01,\n",
       "         -1.0000e+00,  8.3000e+01],\n",
       "        [ 1.0000e+00,         inf,  1.0997e+10,  ...,  2.9700e+01,\n",
       "          6.7526e+05,  6.7000e+01],\n",
       "        [ 1.0000e+00,         inf,  1.0997e+10,  ...,  3.0000e+01,\n",
       "          6.8525e+05,  8.3000e+01],\n",
       "        ...,\n",
       "        [ 3.0000e+00,         inf,  1.0210e+16,  ...,  1.4500e+01,\n",
       "         -1.0000e+00,  8.3000e+01],\n",
       "        [ 3.0000e+00,         inf,  1.0210e+16,  ...,  3.4375e+01,\n",
       "         -1.0000e+00,  8.3000e+01],\n",
       "        [ 3.0000e+00,         inf,  1.0210e+16,  ...,  9.5875e+00,\n",
       "         -1.0000e+00,  8.3000e+01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = torch.unique(sample_tensor, dim=0)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gvlpx-fkAdyq"
   },
   "outputs": [],
   "source": [
    "sample_tensor_modified = sample_tensor\n",
    "sample_tensor_modified[:, 1] = torch.log(sample_tensor[:, 1]) # name -- this column is fucked, just get rid of it\n",
    "sample_tensor_modified[:, 2] = torch.log(sample_tensor[:, 2]) # sex -- I guess I can log-ify it\n",
    "sample_tensor_modified[:, 6] = torch.log(sample_tensor[:, 6]) # ticket -- logify it\n",
    "\n",
    "original_col = sample_tensor[:, 8]\n",
    "modified_column = torch.log(original_col)\n",
    "non_nan_mask = ~torch.isnan(modified_column)\n",
    "sample_tensor_modified[:, 8] = torch.where(non_nan_mask, modified_column, original_col) # cabin -- logify it and mask for nans\n",
    "\n",
    "\n",
    "max_float = torch.finfo(sample_tensor_modified.dtype).max\n",
    "sample_tensor_modified[torch.isinf(sample_tensor_modified)] = max_float\n",
    "sample_ndarray_modified = sample_tensor_modified.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "ZVbasYL6-Frj",
    "outputId": "9e5566d0-e438-4252-9350-8ef19a837351"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the column you want to visualize\n",
    "column_to_visualize = sample_ndarray_modified[:, 8]  # Assuming you want to visualize the first column\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(column_to_visualize, bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "#plt.title('Distribution of the First Column of the Tensor')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1sSlzHwFYZ7",
    "outputId": "db589804-5e5f-4d46-9a73-ecc3c9dd4911"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.       , 13.423435 , -1.       , 18.027565 , -1.       ,\n",
       "       -1.       , 13.452032 , -1.       , -1.       , -1.       ,\n",
       "        8.875427 , 18.027561 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.437691 , -1.       ,  8.78783  , -1.       ,\n",
       "       -1.       , -1.       , 50.263905 , -1.       , -1.       ,\n",
       "       -1.       , 13.408378 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.437394 , -1.       , 13.407764 ,\n",
       "       13.422986 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.407626 , 13.423432 , -1.       , -1.       ,\n",
       "       -1.       , 13.466167 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       22.67384  , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , 50.263905 , -1.       ,\n",
       "       -1.       , -1.       , 13.451881 , -1.       , -1.       ,\n",
       "       -1.       ,  8.787678 , 31.857779 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.437253 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       18.027563 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , 31.828758 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , 18.056763 , 13.437253 ,\n",
       "       -1.       , -1.       , -1.       , 22.673836 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.437547 , 18.027565 , -1.       , 13.408525 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  8.860783 , -1.       ,\n",
       "       -1.       ,  8.817298 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.451884 , -1.       , -1.       , -1.       ,\n",
       "       13.407477 , -1.       , -1.       , -1.       ,  8.787983 ,\n",
       "       -1.       , -1.       , 13.422849 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  8.861067 , -1.       ,\n",
       "       13.392619 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  8.860783 ,  8.802672 ,\n",
       "       13.408516 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "        8.875427 , -1.       , -1.       , -1.       , 13.392618 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.437399 , -1.       , -1.       , 13.437105 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.42358  ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.423432 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.423291 , -1.       , -1.       , 13.437397 , -1.       ,\n",
       "       -1.       ,  8.875427 , 13.423438 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.408377 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.452322 , 13.408672 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , 18.027565 , 13.423589 ,\n",
       "       -1.       , -1.       , -1.       , 18.027563 , -1.       ,\n",
       "        8.832733 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.392324 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.407928 ,  4.2195077, -1.       , -1.       ,\n",
       "       -1.       , -1.       , 31.843224 , 18.027561 , 31.828758 ,\n",
       "       -1.       , -1.       , -1.       , 18.056763 , -1.       ,\n",
       "       31.843224 , -1.       , 13.423139 , -1.       , 13.451889 ,\n",
       "       13.422989 , 68.67012  , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  8.818038 , 13.451886 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.42269  , -1.       ,  4.2195077, -1.       , 13.407476 ,\n",
       "       -1.       , 18.027565 , 13.423577 , -1.       , -1.       ,\n",
       "       -1.       ,  8.817298 , 13.4520235, -1.       ,  4.4308167,\n",
       "        8.860783 , 50.263905 , -1.       , -1.       , -1.       ,\n",
       "       13.466167 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 18.027565 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.451884 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.437401 , -1.       , -1.       , 13.407772 ,\n",
       "       13.4521675, -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.42343  , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       31.829357 , -1.       , -1.       , 13.437399 ,  8.875427 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.423291 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.451592 ,\n",
       "       13.422986 , -1.       , -1.       , -1.       , 13.452029 ,\n",
       "       31.829357 , -1.       , -1.       , 50.263905 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.392623 , -1.       , -1.       , -1.       , 18.027561 ,\n",
       "       -1.       , -1.       , 18.027563 , 13.423578 , -1.       ,\n",
       "       -1.       , 13.451892 , 13.437245 , -1.       , -1.       ,\n",
       "       13.451595 , -1.       , 13.452316 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  4.2195077, -1.       ,\n",
       "       13.392317 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.407928 ,\n",
       "       -1.       , 13.42358  , 13.407775 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.422688 , -1.       , -1.       ,\n",
       "       -1.       , 13.437244 , -1.       , 31.843224 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.40838  ,\n",
       "       13.423139 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.451743 , -1.       , -1.       ,\n",
       "       13.437545 , 13.466167 , -1.       , -1.       , -1.       ,\n",
       "       13.408371 , -1.       , -1.       , 13.407476 , -1.       ,\n",
       "       -1.       , -1.       , 13.423583 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.407777 , -1.       , -1.       , 13.407779 ,\n",
       "       13.407618 , -1.       , -1.       , -1.       , 13.423436 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.42328  , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.392321 , -1.       , 13.452322 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 18.027561 , 13.451743 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.452029 , -1.       , -1.       ,\n",
       "       -1.       , 13.423143 , -1.       , 13.392311 , -1.       ,\n",
       "       13.452323 , -1.       , 13.407917 , -1.       , -1.       ,\n",
       "       -1.       , 13.437244 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.392464 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 18.027565 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       ,  8.861067 , -1.       ,\n",
       "       -1.       , 13.437111 , -1.       , -1.       , -1.       ,\n",
       "       13.437682 , -1.       ,  8.833025 , -1.       , -1.       ,\n",
       "       13.392468 , -1.       , 13.408066 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.407772 , -1.       , -1.       , -1.       ,\n",
       "       13.437394 , -1.       , 13.392473 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.437548 ,\n",
       "       -1.       , -1.       , 13.452179 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 18.027565 ,\n",
       "       -1.       , 13.408367 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 50.249428 ,\n",
       "       -1.       , 13.43755  , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       ,  8.802823 ,\n",
       "       13.407615 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , 13.423143 , 22.67384  ,\n",
       "       31.843815 , 13.451742 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.451742 , -1.       , -1.       ,\n",
       "       13.423575 , 18.027565 , 18.027565 , -1.       , -1.       ,\n",
       "       22.67384  , 13.422843 , 18.056763 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       ,  8.84736  ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "        8.802823 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 18.012634 , -1.       , -1.       ,\n",
       "       13.437544 , 13.422844 , 68.67012  , -1.       , -1.       ,\n",
       "       13.407618 , -1.       , -1.       , 13.43739  , -1.       ,\n",
       "       -1.       , 18.056767 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.408377 ,\n",
       "       -1.       , -1.       , -1.       , 31.829357 , -1.       ,\n",
       "       13.437099 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.452465 , -1.       , -1.       ,\n",
       "       -1.       , 13.466174 , -1.       , -1.       ,  8.802523 ,\n",
       "       -1.       , 13.407615 ,  8.832587 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 31.8292   ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , 13.437108 , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 31.829357 , -1.       , -1.       ,\n",
       "       -1.       , 13.392626 , -1.       , -1.       ,  8.84736  ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       18.012634 , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.408229 , -1.       , -1.       , 18.056767 , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.407626 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       13.452037 , -1.       , -1.       , -1.       , 13.422846 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.423578 ,\n",
       "       -1.       , -1.       , -1.       , 13.437256 , -1.       ,\n",
       "       -1.       , -1.       , 13.451602 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.437108 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.39247  , -1.       , -1.       ,\n",
       "       -1.       , 13.437397 , 50.249428 , -1.       , -1.       ,\n",
       "       -1.       , -1.       , -1.       , -1.       , 13.422983 ,\n",
       "       -1.       , -1.       , -1.       , -1.       , -1.       ,\n",
       "       -1.       , -1.       , 13.407918 , -1.       , 18.027569 ,\n",
       "       -1.       ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ndarray_modified[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtgzXp7g_rMC",
    "outputId": "38acde0e-1971-4e94-f671-6bf88783e08a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00000000e+00,  6.75653000e+05, -1.00000000e+00,  6.74950510e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.95254000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  7.15400000e+03,  6.74948510e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.85354000e+05, -1.00000000e+00,  6.55400000e+03,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.75051327e+21,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65556000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85151000e+05, -1.00000000e+00,  6.65148000e+05,  6.75350000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65056000e+05,  6.75651000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  7.05151000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  7.03271555e+09,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75051327e+21, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95149000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.55300000e+03,  6.84948327e+13, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.85054000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.74949480e+07, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.65356327e+13, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.94948490e+07,\n",
       "        6.85054000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        7.03269546e+09, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85255000e+05,  6.74950510e+07, -1.00000000e+00,  6.65654000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        7.05000000e+03, -1.00000000e+00, -1.00000000e+00,  6.75000000e+03,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.95151000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.64957000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.55500000e+03, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75257000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  7.05200000e+03,\n",
       "       -1.00000000e+00,  6.55150000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  7.05000000e+03,  6.65200000e+03,  6.65648000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  7.15400000e+03, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.55149000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.85154000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.84953000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75751000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75651000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75556000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85153000e+05, -1.00000000e+00, -1.00000000e+00,  7.15400000e+03,\n",
       "        6.75655000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65555000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.95455000e+05,  6.65752000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.74950530e+07,  6.75757000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.74949560e+07, -1.00000000e+00,  6.85500000e+03,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.54957000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65257000e+05,\n",
       "        6.80000000e+01, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75050327e+13,  6.74948540e+07,  6.65356327e+13,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.94948490e+07,\n",
       "       -1.00000000e+00,  6.75050327e+13, -1.00000000e+00,  6.75453000e+05,\n",
       "       -1.00000000e+00,  6.95154000e+05,  6.75352000e+05,  6.65355327e+29,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75500000e+03,  6.95152000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75150000e+05, -1.00000000e+00,  6.80000000e+01,\n",
       "       -1.00000000e+00,  6.64956000e+05, -1.00000000e+00,  6.74950520e+07,\n",
       "        6.75749000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75000000e+03,  6.95248000e+05, -1.00000000e+00,  8.40000000e+01,\n",
       "        7.05000000e+03,  6.75051327e+21, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  7.05151000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.74950560e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95151000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.85155000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65153000e+05,  6.95348000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75650000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.65754327e+13, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.85154000e+05,  7.15400000e+03, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75556000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.94948000e+05,  6.75350000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.95252000e+05,  6.65754327e+13,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75051327e+21, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.55152000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.74948520e+07, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.74949490e+07,  6.75750000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95156000e+05,  6.85049000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.94950000e+05, -1.00000000e+00,  6.95451000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.80000000e+01, -1.00000000e+00,  6.54952000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.65257000e+05, -1.00000000e+00,  6.75751000e+05,  6.65155000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75148000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85048000e+05, -1.00000000e+00,  6.75050327e+13, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.65557000e+05,  6.75453000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95053000e+05, -1.00000000e+00, -1.00000000e+00,  6.85254000e+05,\n",
       "        7.05151000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.65551000e+05, -1.00000000e+00, -1.00000000e+00,  6.64956000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.75753000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.65156000e+05, -1.00000000e+00, -1.00000000e+00,  6.65157000e+05,\n",
       "        6.65050000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.75654000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75548000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.54954000e+05, -1.00000000e+00,  6.95455000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.74948490e+07,\n",
       "        6.95053000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.95252000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75456000e+05, -1.00000000e+00,  6.54948000e+05,\n",
       "       -1.00000000e+00,  6.95456000e+05, -1.00000000e+00,  6.65249000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.85048000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.55048000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.74950530e+07, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  7.05200000e+03, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.84957000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.85348000e+05, -1.00000000e+00,  6.85700000e+03,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.55051000e+05, -1.00000000e+00,\n",
       "        6.65348000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65153000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.85151000e+05, -1.00000000e+00,  6.55054000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.85256000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.95356000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.74950540e+07, -1.00000000e+00,  6.65549000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65349327e+21,\n",
       "       -1.00000000e+00,  6.85257000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65300000e+03,  6.65048000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75456000e+05,  7.03271545e+09,\n",
       "        6.75450327e+13,  6.95052000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.95052000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.75748000e+05,  6.74950520e+07,\n",
       "        6.74950540e+07, -1.00000000e+00, -1.00000000e+00,  7.03271555e+09,\n",
       "        6.75253000e+05,  6.94948490e+07, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95600000e+03, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.65300000e+03, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.64948490e+07, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85253000e+05,  6.75254000e+05,  6.65355327e+29, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65050000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.85148000e+05, -1.00000000e+00, -1.00000000e+00,  6.94950490e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65555000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65754327e+13,\n",
       "       -1.00000000e+00,  6.84949000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.95555000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        7.05156000e+05, -1.00000000e+00, -1.00000000e+00,  6.65100000e+03,\n",
       "       -1.00000000e+00,  6.65048000e+05,  6.85400000e+03, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65650327e+13, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.84955000e+05, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.65754327e+13, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.55154000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.95600000e+03, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.64948500e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "        6.65457000e+05, -1.00000000e+00, -1.00000000e+00,  6.94950490e+07,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.65056000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.95257000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.75255000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.75750000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.85056000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00,  6.94955000e+05, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00,  6.84955000e+05, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.55052000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.85153000e+05,\n",
       "        6.65349327e+21, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.75348000e+05,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,\n",
       "       -1.00000000e+00, -1.00000000e+00, -1.00000000e+00,  6.65250000e+05,\n",
       "       -1.00000000e+00,  6.74952560e+07, -1.00000000e+00])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ndarray[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T01:08:52.645376Z",
     "iopub.status.busy": "2024-02-10T01:08:52.644722Z",
     "iopub.status.idle": "2024-02-10T01:08:52.678738Z",
     "shell.execute_reply": "2024-02-10T01:08:52.676829Z",
     "shell.execute_reply.started": "2024-02-10T01:08:52.64534Z"
    },
    "id": "1GEfsDq7c6im"
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    mean = torch.mean(x, dim=0)\n",
    "    std = torch.std(x, dim=0)\n",
    "    return (x - mean) / std\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        #tensorize = lambda x: torch.tensor(x, dtype=torch.float64)\n",
    "        self.features = list(map(lambda x: torch.tensor(x, dtype=torch.float64), features))\n",
    "        self.targets = list(map(lambda x: torch.tensor(x, dtype=torch.long), targets))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.targets[index]\n",
    "\n",
    "norm_samps = normalize(torch.tensor(samples, dtype=torch.float64)).tolist()\n",
    "my_dataset = MyDataset(norm_samps, targets)\n",
    "\n",
    "train_size = int(0.85 * len(my_dataset))\n",
    "eval_size = len(my_dataset) - train_size\n",
    "\n",
    "train_dataset, eval_dataset = random_split(my_dataset, [train_size, eval_size])\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T01:09:11.564084Z",
     "iopub.status.busy": "2024-02-10T01:09:11.563498Z",
     "iopub.status.idle": "2024-02-10T01:09:11.577835Z",
     "shell.execute_reply": "2024-02-10T01:09:11.576736Z",
     "shell.execute_reply.started": "2024-02-10T01:09:11.564039Z"
    },
    "id": "6Y125obcc6im"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.l1 = nn.Linear(10, 128, dtype=torch.float64)\n",
    "        self.l2 = nn.Linear(128, 128, dtype=torch.float64)\n",
    "        self.l3 = nn.Linear(128, 128, dtype=torch.float64)\n",
    "        self.l4 = nn.Linear(128, 128, dtype=torch.float64)\n",
    "        self.l5 = nn.Linear(128, 128, dtype=torch.float64)\n",
    "        self.l6 = nn.Linear(128, 64, dtype=torch.float64)\n",
    "        self.l7 = nn.Linear(64, 32, dtype=torch.float64)\n",
    "        self.l8 = nn.Linear(32, 16, dtype=torch.float64)\n",
    "        self.l9 = nn.Linear(16, 8, dtype=torch.float64)\n",
    "        self.l10 = nn.Linear(8, 4, dtype=torch.float64)\n",
    "        self.l11 = nn.Linear(4, 2, dtype=torch.float64)\n",
    "\n",
    "        init.xavier_uniform_(self.l1.weight)\n",
    "        init.xavier_uniform_(self.l2.weight)\n",
    "        init.xavier_uniform_(self.l3.weight)\n",
    "        init.xavier_uniform_(self.l4.weight)\n",
    "        init.xavier_uniform_(self.l5.weight)\n",
    "        init.xavier_uniform_(self.l6.weight)\n",
    "        init.xavier_uniform_(self.l7.weight)\n",
    "        init.xavier_uniform_(self.l8.weight)\n",
    "        init.xavier_uniform_(self.l9.weight)\n",
    "        init.xavier_uniform_(self.l10.weight)\n",
    "        init.xavier_uniform_(self.l11.weight)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l11(\n",
    "            self.leakyrelu(self.l10(\n",
    "            self.leakyrelu(self.l9(\n",
    "            self.leakyrelu(self.l8(\n",
    "            self.leakyrelu(self.l7(\n",
    "            self.leakyrelu(self.l6(\n",
    "            self.leakyrelu(self.l5(\n",
    "            self.leakyrelu(self.l4(\n",
    "            self.leakyrelu(self.l3(\n",
    "            self.leakyrelu(self.l2(\n",
    "            self.leakyrelu(self.l1(x)))))))))))))))))))))\n",
    "\n",
    "# this should really be in Model\n",
    "def predict(model, sample):\n",
    "  predictions = model(sample).squeeze()\n",
    "  best_i, best_prob = 0, predictions[0]\n",
    "  for i in range(1, len(predictions)):\n",
    "    if predictions[i] > best_prob:\n",
    "        best_i, best_prob = i, predictions[i]\n",
    "  return best_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-10T01:09:17.291234Z",
     "iopub.status.busy": "2024-02-10T01:09:17.290748Z",
     "iopub.status.idle": "2024-02-10T01:09:17.298889Z",
     "shell.execute_reply": "2024-02-10T01:09:17.297787Z",
     "shell.execute_reply.started": "2024-02-10T01:09:17.291196Z"
    },
    "id": "y8EvKrWEc6ip"
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-10T01:41:13.117323Z",
     "iopub.status.busy": "2024-02-10T01:41:13.116851Z",
     "iopub.status.idle": "2024-02-10T01:44:13.787124Z",
     "shell.execute_reply": "2024-02-10T01:44:13.785722Z",
     "shell.execute_reply.started": "2024-02-10T01:41:13.117289Z"
    },
    "id": "HDDRIH5_c6iq",
    "outputId": "7062869e-5ad3-4b8b-8b4f-82bc9adc54ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 180.57594671364873\n",
      "Epoch 2 loss: 180.57487740862632\n",
      "Epoch 3 loss: 180.57404728858185\n",
      "Epoch 4 loss: 180.57285124136428\n",
      "Epoch 5 loss: 180.57185187438066\n",
      "Epoch 6 loss: 180.570647788244\n",
      "Epoch 7 loss: 180.5698597826266\n",
      "Epoch 8 loss: 180.5692789795778\n",
      "Epoch 9 loss: 180.56835008978754\n",
      "Epoch 10 loss: 180.56686304450898\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr = 0.000001\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        ins, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outs = model(ins)\n",
    "        #print(outs, labels)\n",
    "        loss = criterion(outs, labels)\n",
    "        #print(loss)\n",
    "        #print(loss.size())\n",
    "        #print(loss.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1} loss: {epoch_loss}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "OM6DSQEvc6ir"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TF_TaPnZfEGb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f02Y2zqQfECH",
    "outputId": "23d9b0cf-e583-4e93-bfa8-41a120a46d9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78502\n"
     ]
    }
   ],
   "source": [
    "# print parameter count\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1_ELoWZfD--",
    "outputId": "b2ba2a9d-c400-485c-db02-94fe718b9b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5652, -0.0000,  1.3548,  0.3582,  0.6814,  0.5601, -0.0842,  0.4827,\n",
      "         -0.0474, -1.7321]], dtype=torch.float64)\n",
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# print sample and label of a random datapoint\n",
    "for batch in train_loader:\n",
    "    ins, lbls = batch\n",
    "    print(ins)\n",
    "    print(lbls)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWW8oztyhQWx",
    "outputId": "4e93bddc-42fd-4537-8839-605299ad381c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1882,  0.0417,  0.1344,  ..., -0.1266,  0.0709, -0.1948],\n",
      "        [ 0.0809,  0.1979, -0.1637,  ...,  0.0078, -0.1980,  0.1443],\n",
      "        [ 0.0949, -0.1445,  0.1798,  ...,  0.1913, -0.0129, -0.2070],\n",
      "        ...,\n",
      "        [-0.0589,  0.1539,  0.1891,  ...,  0.0033, -0.0295, -0.2041],\n",
      "        [ 0.0160, -0.1946, -0.0840,  ..., -0.0329,  0.1356, -0.0375],\n",
      "        [-0.1298,  0.0718, -0.1236,  ...,  0.1035, -0.0308, -0.1298]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1787, -0.0261, -0.0845, -0.2812,  0.2499,  0.1371, -0.0737, -0.1580,\n",
      "        -0.2576, -0.2254,  0.1206,  0.0285, -0.0928,  0.1375, -0.2319, -0.2196,\n",
      "         0.2096,  0.3126, -0.2185,  0.0242,  0.0511, -0.2590, -0.0502, -0.0126,\n",
      "         0.2660,  0.2276,  0.2127, -0.1135,  0.1478,  0.0352, -0.0652, -0.2142,\n",
      "         0.0649,  0.3095, -0.0339,  0.0113,  0.0727,  0.0459,  0.2704, -0.1651,\n",
      "        -0.2444, -0.0033, -0.0086,  0.2405,  0.1585,  0.2560,  0.0291,  0.1131,\n",
      "        -0.1054,  0.2527, -0.0996,  0.2243, -0.2962,  0.0340,  0.0216,  0.2543,\n",
      "        -0.1293,  0.1131, -0.3115, -0.1559,  0.2830, -0.2808,  0.0665,  0.2292,\n",
      "         0.2928,  0.0061,  0.2406,  0.2820, -0.1960, -0.0040, -0.2521,  0.0249,\n",
      "         0.1756,  0.2946, -0.0110,  0.2763,  0.1505, -0.2048,  0.2472,  0.0501,\n",
      "        -0.1485,  0.2616, -0.1897,  0.0197, -0.2593, -0.1512, -0.0231,  0.0227,\n",
      "         0.2241, -0.2510,  0.0355,  0.0139,  0.1098, -0.1262,  0.2123, -0.1667,\n",
      "         0.0551,  0.2187,  0.1108, -0.1613, -0.0034, -0.2186, -0.2309,  0.3131,\n",
      "         0.2360,  0.1986, -0.2059, -0.1788, -0.0294,  0.0886, -0.1913, -0.1182,\n",
      "        -0.1383, -0.2712, -0.2048,  0.1160, -0.2906,  0.0169, -0.2339, -0.1958,\n",
      "         0.2520, -0.0351, -0.0434,  0.1078,  0.0647, -0.1775, -0.2061, -0.0537],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print params (before training)\n",
    "for _, param in model.l1.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KzEn1ORPhzjf",
    "outputId": "a290d9fc-e300-47e7-b660-a5ce1a67f68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4525,  0.0417,  0.5834,  ..., -0.2398,  0.0831, -0.2615],\n",
      "        [ 0.0755,  0.1979, -0.1699,  ..., -0.0210, -0.1923,  0.1884],\n",
      "        [ 0.1168, -0.1445,  0.2404,  ...,  0.2697, -0.0041, -0.1796],\n",
      "        ...,\n",
      "        [-0.1878,  0.1539,  0.2323,  ...,  0.0637, -0.0205, -0.3001],\n",
      "        [-0.1156, -0.1946, -0.2763,  ...,  0.0172,  0.1264, -0.1373],\n",
      "        [ 0.0087,  0.0718, -0.1556,  ...,  0.3245, -0.0283, -0.1450]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2973, -0.1476, -0.0966, -0.2427,  0.1541,  0.1073, -0.0707, -0.2312,\n",
      "        -0.3669, -0.2362,  0.0332, -0.0434, -0.1305,  0.0500, -0.3289, -0.2467,\n",
      "         0.1177,  0.0793, -0.1441, -0.1685,  0.0568, -0.2402, -0.1727,  0.0308,\n",
      "         0.1898,  0.1037,  0.1362, -0.2224,  0.0298, -0.0240, -0.1450, -0.2501,\n",
      "        -0.0015,  0.1393, -0.1146, -0.0233, -0.0379, -0.0090,  0.0997, -0.1843,\n",
      "        -0.2788, -0.0118, -0.0062,  0.0936,  0.0836,  0.2171, -0.0619, -0.0014,\n",
      "        -0.0908,  0.1726, -0.0709,  0.0838, -0.3138,  0.0969,  0.0516,  0.2430,\n",
      "        -0.1784,  0.0681, -0.3294, -0.2634,  0.2750, -0.3037,  0.0486,  0.0570,\n",
      "         0.2318, -0.0320,  0.1206,  0.2189, -0.2321,  0.0248, -0.2156, -0.0037,\n",
      "         0.1068,  0.2628, -0.0335,  0.1570,  0.0284, -0.2394,  0.2447,  0.0093,\n",
      "        -0.2432,  0.1324, -0.1989, -0.0865, -0.2906, -0.1339, -0.0585, -0.0852,\n",
      "         0.1249, -0.2542, -0.0028, -0.0224, -0.0319, -0.1844,  0.0093, -0.2325,\n",
      "         0.0388,  0.1686,  0.0883, -0.1604, -0.0637, -0.2219, -0.2373,  0.2678,\n",
      "         0.0991,  0.1586, -0.2748, -0.1963, -0.1124, -0.0165, -0.1987, -0.0741,\n",
      "        -0.3080, -0.2465, -0.2266,  0.1030, -0.3369, -0.0566, -0.2474, -0.1315,\n",
      "         0.1938, -0.1636, -0.0069,  0.0676,  0.0023, -0.2215, -0.1871, -0.0570],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#print params (after training)\n",
    "for _, param in model.l1.named_parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ug-g0nP7hzg_",
    "outputId": "00864f34-c0c9-4fe9-b976-9299700fa33a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1:\n",
      "tensor([0])\n",
      "tensor([[ 2.1752, -8.6576]], dtype=torch.float64, grad_fn=<AddmmBackward0>)\n",
      "0\n",
      "tensor(1.9741e-05, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print N examples of the model's predictions\n",
    "N = 1\n",
    "for i in range(N):\n",
    "    for batch in train_loader:\n",
    "        ins, lbls = batch\n",
    "        out = model(ins)\n",
    "        probs = torch.log(out)\n",
    "        loss = criterion(model(ins), lbls)\n",
    "        prediction = predict(model, ins)\n",
    "        #loss = F.cross_entropy(out, lbls)\n",
    "        #print(ins)\n",
    "        print(f'sample {i+1}:')\n",
    "        print(lbls)\n",
    "        print(out)\n",
    "        print(prediction)\n",
    "        #print(probs)\n",
    "        print(loss)\n",
    "        print()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2HmLYhSucHj",
    "outputId": "6beae7ca-d6eb-48a2-fa11-c35b1f77e31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 correct out of 134: 0.7835820895522388%\n"
     ]
    }
   ],
   "source": [
    "#EVAL\n",
    "\n",
    "# MAX = 100\n",
    "# i = 0\n",
    "correct, total = 0, 0\n",
    "for batch in eval_loader:\n",
    "  # if i > MAX:\n",
    "  #   break\n",
    "\n",
    "  [s, t] = batch\n",
    "  #print(f'target: {t.item()}\\teval: {model(s)}\\tpredict: {predict(model, s)}\\t{correct}/{total}')\n",
    "  correct, total = correct + (1 if predict(model, s) == t.item() else 0), total + 1\n",
    "\n",
    "  # i = i + 1\n",
    "print(f'{correct} correct out of {total}: {correct/total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn8F723-ub-D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aa89cVVoub6c"
   },
   "outputs": [],
   "source": [
    "input_path = '../input/titanic/test.csv'\n",
    "\n",
    "with open(input_path, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    _ = next(reader)\n",
    "    test_samples = []\n",
    "    test_ids = []\n",
    "\n",
    "    for row in reader:\n",
    "        id = int(row[0])\n",
    "        test_ids.append(id)\n",
    "\n",
    "        samp = [str_to_float(v) for v in row[1:]]\n",
    "        test_samples.append(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwF7FKGLyjBk"
   },
   "outputs": [],
   "source": [
    "norm_test_samps = normalize(torch.tensor(test_samples, dtype=torch.float64)).tolist()\n",
    "my_test_dataset = MyDataset(norm_test_samps, test_ids)\n",
    "batch_size = 1\n",
    "test_loader = DataLoader(my_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pC-42X8ksd5k"
   },
   "outputs": [],
   "source": [
    "# Opening the file in write mode with 'newline' parameter to avoid extra spacing\n",
    "with open('submission1.csv', 'w', newline='') as csvfile:\n",
    "    # Creating a CSV writer object\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "\n",
    "    # Writing the header row\n",
    "    csv_writer.writerow(['PassengerId', 'Survived'])\n",
    "\n",
    "    # Iterating through the test loader\n",
    "    for batch in test_loader:\n",
    "        # Extracting the features and IDs from the batch\n",
    "        s, id = batch\n",
    "\n",
    "        # Writing the ID and predicted value to the CSV file\n",
    "        csv_writer.writerow([id.item(), predict(model, s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OafLorlymjT",
    "outputId": "7e2d05a8-3eaa-4fc7-9282-92c70bf324f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKTTjOzf0eS3"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7uJvYWB1Dxf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gw2hK_ET1I7w",
    "outputId": "33ec403a-4896-4d0b-f030-8fb0c2e6756a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Model()\n",
    "model2.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5S0FgvL1RJn",
    "outputId": "f60fadfd-f50a-4898-fd7b-1d010e75beaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 correct out of 134: 0.7835820895522388%\n"
     ]
    }
   ],
   "source": [
    "#EVAL\n",
    "\n",
    "# MAX = 100\n",
    "# i = 0\n",
    "correct, total = 0, 0\n",
    "for batch in eval_loader:\n",
    "  # if i > MAX:\n",
    "  #   break\n",
    "\n",
    "  [s, t] = batch\n",
    "  #print(f'target: {t.item()}\\teval: {model(s)}\\tpredict: {predict(model, s)}\\t{correct}/{total}')\n",
    "  correct, total = correct + (1 if predict(model2, s) == t.item() else 0), total + 1\n",
    "\n",
    "  # i = i + 1\n",
    "print(f'{correct} correct out of {total}: {correct/total}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oMJdPpB1TeF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
